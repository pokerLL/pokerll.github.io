(window.webpackJsonp=window.webpackJsonp||[]).push([[44],{325:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"str"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#str"}},[t._v("#")]),t._v(" str")]),t._v(" "),s("h2",{attrs:{id:"python中的unicode"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#python中的unicode"}},[t._v("#")]),t._v(" python中的unicode")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("Python 在 3 之后，str 对象内部改用 Unicode 表示，因而被源码称为 Unicode 对象。这么做的好处是程序核心逻辑统一用 Unicode ，只需在输入、输入层进行编码、解码，可最大程度避免各种编码问题。")]),t._v(" "),s("p",[t._v("​"),s("img",{attrs:{src:"https://assets.b3logfile.com/siyuan/xxxxxx/assets/image-20230211230948-i6ji9a5.png",alt:"image"}}),t._v("​")])]),t._v(" "),s("li",[s("p",[t._v("由于Unicode 收录字符已经超过 13 万个，每个字符至少需要 4 个字节来保存。cpython源码中对此做了一定优化-根据文本内容选择底层存储单元。")]),t._v(" "),s("ul",[s("li",[t._v("Go对此类似的全部采用了UTF-8编码来解决这个问题字符串")]),t._v(" "),s("li",[t._v("可考虑变长存储-英文1字节，中文2字节，但是采用变长存储单元后，就无法在 O(1) 时间内取出文本第 n 个字符—只能从头遍历直到第 n 个字符。")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v(">>> import sys\n# 英文字符需要1字节\n>>> sys.getsizeof('ab') - sys.getsizeof('a')\n1\n# 中文字符需要2字节\n>>> sys.getsizeof('中国') - sys.getsizeof('中')\n2\n# Emoji表情需要4字节\n# 注意这里是显示问题所以实际测试时直接复制代码的话结果为1\n>>> sys.getsizeof('??') - sys.getsizeof('?')\n4\n")])])])])]),t._v(" "),s("p",[t._v("‍")]),t._v(" "),s("h2",{attrs:{id:"内部实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#内部实现"}},[t._v("#")]),t._v(" 内部实现")]),t._v(" "),s("h3",{attrs:{id:"文本类型与存储结果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文本类型与存储结果"}},[t._v("#")]),t._v(" 文本类型与存储结果")]),t._v(" "),s("p",[t._v("在 "),s("code",[t._v("Include/unicodeobject.h")]),t._v("​ 头文件中，可以发现 str 对象底层存储根据文本字符 Unicode 码位范围分成几类：")]),t._v(" "),s("ul",[s("li",[t._v("​"),s("code",[t._v("PyUnicode_1BYTE_KIND")]),t._v("​ ，所有字符码位均在 U+0000 到 U+00FF 之间，对此使用"),s("code",[t._v("uint_8")]),t._v("​来进行存储。")]),t._v(" "),s("li",[t._v("​"),s("code",[t._v("PyUnicode_2BYTE_KIND")]),t._v("​ ，所有字符码位均在 U+0000 到 U+FFFF 之间，且至少一个大于 U+00FF，对此使用"),s("code",[t._v("uint_16")]),t._v("​来进行存储。")]),t._v(" "),s("li",[t._v("​"),s("code",[t._v("PyUnicode_4BYTE_KIND")]),t._v("​ ，所有字符码位均在 U+0000 到 U+10FFFF 之间，且至少一个大于 U+FFFF，对此使用"),s("code",[t._v("uint_32")]),t._v("​来进行存储。")])]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[s("strong",[t._v("文本类型")])]),t._v(" "),s("th",[s("strong",[t._v("字符存储单元")])]),t._v(" "),s("th",[s("strong",[t._v("字符存储单元大小（字节）")])])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("PyUnicode_1BYTE_KIND")]),t._v(" "),s("td",[t._v("Py_UCS1")]),t._v(" "),s("td",[t._v("1")])]),t._v(" "),s("tr",[s("td",[t._v("PyUnicode_2BYTE_KIND")]),t._v(" "),s("td",[t._v("Py_UCS2")]),t._v(" "),s("td",[t._v("2")])]),t._v(" "),s("tr",[s("td",[t._v("PyUnicode_4BYTE_KIND")]),t._v(" "),s("td",[t._v("Py_UCS4")]),t._v(" "),s("td",[t._v("4")])])])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("enum PyUnicode_Kind "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" String contains only wstr byte characters"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  This "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" only possible\n   when the string was created "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" a legacy API "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" _PyUnicode_Ready"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   has "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" been called yet"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n    PyUnicode_WCHAR_KIND "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" Return values of the PyUnicode_KIND"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" macro"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n    PyUnicode_1BYTE_KIND "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    PyUnicode_2BYTE_KIND "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    PyUnicode_4BYTE_KIND "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("typedef uint32_t Py_UCS4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ntypedef uint16_t Py_UCS2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ntypedef uint8_t Py_UCS1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("Python Unicode内部存储结果因文本类型而不同，因此采用了哪种字符存储单元必须作为Unicode公共字段进行保存，类似的还有：")]),t._v(" "),s("ul",[s("li",[t._v("interned ，是否为 interned 机制维护")]),t._v(" "),s("li",[t._v("kind ，类型，用于区分字符底层存储单元大小")]),t._v(" "),s("li",[t._v("compact ，内存分配方式，对象与文本缓冲区是否分离")]),t._v(" "),s("li",[t._v("ascii ，文本是否均为纯 ASCII")])]),t._v(" "),s("p",[t._v("​"),s("code",[t._v("Objects/unicodectype.c")]),t._v("​ 源文件中的 "),s("code",[t._v("PyUnicode_New")]),t._v("​ 函数，根据文本字符数 "),s("code",[t._v("size")]),t._v("​以及最大字符 "),s("code",[t._v("maxchar")]),t._v("​初始化 "),s("code",[t._v("Unicode")]),t._v("​对象。该函数根据 "),s("code",[t._v("maxchar")]),t._v("​为 "),s("code",[t._v("Unicode")]),t._v("​对象选择最紧凑的字符存储单元以及底层结构体：")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th"),t._v(" "),s("th",[t._v("​"),s("code",[t._v("maxchar < 128")]),t._v("​")]),t._v(" "),s("th",[t._v("​"),s("code",[t._v("maxchar < 256")]),t._v("​")]),t._v(" "),s("th",[t._v("​"),s("code",[t._v("maxchar < 65536")]),t._v("​")]),t._v(" "),s("th",[t._v("​"),s("code",[t._v("maxchar < MAX_UNICODE")]),t._v("​")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("kind")]),t._v(" "),s("td",[t._v("PyUnicode_1BYTE_KIND")]),t._v(" "),s("td",[t._v("PyUnicode_1BYTE_KIND")]),t._v(" "),s("td",[t._v("PyUnicode_2BYTE_KIND")]),t._v(" "),s("td",[t._v("PyUnicode_4BYTE_KIND")])]),t._v(" "),s("tr",[s("td",[t._v("ascii")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("0")]),t._v(" "),s("td",[t._v("0")]),t._v(" "),s("td",[t._v("0")])]),t._v(" "),s("tr",[s("td",[t._v("字符存储单元大小")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("2")]),t._v(" "),s("td",[t._v("4")])]),t._v(" "),s("tr",[s("td",[t._v("底层结构体")]),t._v(" "),s("td",[t._v("PyASCIIObject")]),t._v(" "),s("td",[t._v("PyCompactUnicodeObject")]),t._v(" "),s("td",[t._v("PyCompactUnicodeObject")]),t._v(" "),s("td",[t._v("PyCompactUnicodeObject")])])])]),t._v(" "),s("p",[t._v("根据试验可以看出，在指定了kind类型后，其内部所有字符都以这种方式进行保存。")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("49")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'中'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("76")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'中国'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("78")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'中国a'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ab'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("51")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a中'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("78")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getsizeof"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ab中'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),t._v("\n")])])]),s("p",[t._v("‍")]),t._v(" "),s("h3",{attrs:{id:"pyasciiobject"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pyasciiobject"}},[t._v("#")]),t._v(" PyASCIIObject")]),t._v(" "),s("ul",[s("li",[t._v("如果 str 对象保存的文本均为 "),s("code",[t._v("ASCII")]),t._v("​，即 "),s("code",[t._v("maxchar<128")]),t._v("​​​，则底层由 "),s("code",[t._v("PyASCIIObject")]),t._v("​ 结构存储")]),t._v(" "),s("li",[t._v("同时"),s("code",[t._v("PyASCIIObject")]),t._v("​也似乎其他"),s("code",[t._v("Unicode")]),t._v("​底层存储结构体的基础，所有字段均为"),s("code",[t._v("Unicode")]),t._v("​公共字段。")]),t._v(" "),s("li",[t._v("注意，与"),s("code",[t._v("Unicode")]),t._v("​一致，"),s("code",[t._v("PyASCIIObject")]),t._v("​也会在结构体末尾加上"),s("code",[t._v("\\0")]),t._v("​字节以此兼容C字符串。")]),t._v(" "),s("li",[t._v("因此对于长度为n的纯ANCII字符串对象，需要消耗"),s("code",[t._v("n+48+1")]),t._v("​字节的内存空间。")]),t._v(" "),s("li",[t._v("注意，字符串虽然是变长对象，但是使用的是"),s("code",[t._v("PyObject_HEAD")]),t._v("​​，因为"),s("code",[t._v("PyObject_VAR_HEAD")]),t._v("​用于描述每个元素大小都一样的变长对象，元素大小由类型对象"),s("code",[t._v("tp_itemsize")]),t._v("​字段描述。而str对象，每个元素(字符)到底用多大的存储单元，与字符范围有关，因此底层作了特殊处理。")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" ASCII"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("only strings created through PyUnicode_New use the PyASCIIObject\n   structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("ascii")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compact are "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("set")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" the data\n   immediately follow the structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" utf8_length "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" wstr_length can be found\n   "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" the length field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" the utf8 pointer "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" equal to the data pointer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\ntypedef struct "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    PyObject_HEAD\n    Py_ssize_t length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("          "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" Number of code points "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" the string "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n    Py_hash_t "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("hash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("             "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" Hash value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("set")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n    struct "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        unsigned "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" interned"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        unsigned "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" kind"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        unsigned "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" compact"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        unsigned "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("ascii")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        unsigned "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" ready"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        unsigned "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    wchar_t "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("wstr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("              "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" wchar_t representation "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("null"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("terminated"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" PyASCIIObject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("注意会出现一个4字节的内存空洞做内存对齐用。")]),t._v(" "),s("p",[t._v("​"),s("img",{attrs:{src:"https://assets.b3logfile.com/siyuan/xxxxxx/assets/image-20230211235540-jxobxyu.png",alt:"image"}}),t._v("​")]),t._v(" "),s("p",[t._v("‍")]),t._v(" "),s("h3",{attrs:{id:"pycompactunicodeobject"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#pycompactunicodeobject"}},[t._v("#")]),t._v(" PyCompactUnicodeObject")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("如果文本不全是ANCII，"),s("code",[t._v("Unicode")]),t._v("​对象底层便由"),s("code",[t._v("PyCompactUnicodeObject")]),t._v("​结构体来保存。")])]),t._v(" "),s("li",[s("p",[t._v("​"),s("code",[t._v("PyCompactUnicodeObject")]),t._v("​结构体在"),s("code",[t._v("PyASCIIObject")]),t._v("​结构体的基础上增加了"),s("code",[t._v("utf8_length、utf_7、wstr_length")]),t._v("​三个字段分别保存文本 UTF8 编码长度以及文本 UTF8 编码形式（"),s("code",[t._v("wstr_length")]),t._v("​暂不涉及）。")]),t._v(" "),s("ul",[s("li",[t._v("ASCII本身即是合法的UTF8，无需保存UTF8编码形式，这也是ASCII文本底层由PyASCIIObject保存的原因。")])])])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" Non"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("ASCII strings allocated through PyUnicode_New use the\n   PyCompactUnicodeObject structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compact "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("set")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" the data\n   immediately follow the structure"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\ntypedef struct "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    PyASCIIObject _base"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    Py_ssize_t utf8_length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" Number of "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("bytes")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" utf8"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" excluding the\n                                 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" terminating \\"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n    char "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("utf8"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("                 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" UTF"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v(" representation "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("null"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("terminated"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n    Py_ssize_t wstr_length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" Number of code points "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" wstr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" possible\n                                 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" surrogates count "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" two code points"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" PyCompactUnicodeObject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("‍")]),t._v(" "),s("h2",{attrs:{id:"内存优化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#内存优化"}},[t._v("#")]),t._v(" 内存优化")]),t._v(" "),s("h3",{attrs:{id:"interned机制-编译时优化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#interned机制-编译时优化"}},[t._v("#")]),t._v(" interned机制 - 编译时优化")]),t._v(" "),s("blockquote",[s("p",[t._v("注意，这种优化可能随着版本变更而变化，不可以将程序逻辑建立在这些优化之上。")])]),t._v(" "),s("p",[t._v("考虑如下场景，如果程序中存在大量User对象，有什么可优化的地方：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("User")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("         self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("         self"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" age\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" user "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" User"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tom'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" age"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" user"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__dict__\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tom'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("由于对象的属性由dict保存，这意味着每个User对象都将保存str对象name，即使是一样的name也会创建很多份，将会浪费不少内存空间。")]),t._v(" "),s("p",[t._v("因为str是不可变对象，因此Python有潜在可能将重复的字符串做成单例模式，即interned机制。")]),t._v(" "),s("p",[t._v("具体做法是在内部为一个全局dict对象，所有开启interned机制的str对象均保存在这里，后续需要用到相关对象的地方则优先到全局dict中取，避免重复创建。")]),t._v(" "),s("p",[t._v("这个dict对象key、value都是被缓存的str对象，大致思路：")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("Python先创建一个字符串对象s；")])]),t._v(" "),s("li",[s("p",[t._v("dict里面可能已经缓存了相同的对象ss；")])]),t._v(" "),s("li",[s("p",[t._v("Python执行dict.setdefault(s, s)，这一步分为两种情况：")]),t._v(" "),s("ol",[s("li",[t._v("dict缓存了相同对象ss，setdefault返回ss，Python那ss替换s，这样就保证相同str对象只有一个实例")]),t._v(" "),s("li",[t._v("如果dict未缓存s，就会缓存s，key和value都是s，这样一来后续创建跟s相同的新对象时，都会被s替换。")])])])]),t._v(" "),s("p",[t._v("例如：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("s1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),t._v("\ns2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ab'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),t._v("\ns3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'abc'")]),t._v("\ns4 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bc'")]),t._v("\ns5 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'abc'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\np "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\ns6 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'abc'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" p\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" item "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("s1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s5"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s6"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n140699274168160\n140699274168160\n140699274168160\n140699274168160\n140699274168160\n140699274168160\n"""')]),t._v("\n")])])]),s("p",[t._v("‍")]),t._v(" "),s("h2",{attrs:{id:"qa"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#qa"}},[t._v("#")]),t._v(" QA")]),t._v(" "),s("h3",{attrs:{id:"为什么使用pyobject-head而不是pyobject-var-head"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用pyobject-head而不是pyobject-var-head"}},[t._v("#")]),t._v(" 为什么使用PyObject_HEAD而不是PyObject_VAR_HEAD")]),t._v(" "),s("p",[t._v("PyObject_VAR_HEAD用于描述每个元素大小都一样的变长对象，元素大小由类型对象tp_itemsize字段描述。而str对象，每个元素(字符)到底用多大的存储单元，与字符范围有关，因此底层作了特殊处理。")]),t._v(" "),s("p",[t._v("​#TODO#​")]),t._v(" "),s("p",[t._v("‍")])])}),[],!1,null,null,null);s.default=e.exports}}]);