(window.webpackJsonp=window.webpackJsonp||[]).push([[167],{446:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"数据输入"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据输入"}},[t._v("#")]),t._v(" 数据输入")]),t._v(" "),s("h2",{attrs:{id:"文件读取"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文件读取"}},[t._v("#")]),t._v(" 文件读取")]),t._v(" "),s("p",[t._v("常用函数如下：")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"left"}},[t._v("函数")]),t._v(" "),s("th",[t._v("说明")])])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_csv")]),t._v(" "),s("td",[t._v("读取默认以逗号作为分隔符的文件")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_table")]),t._v(" "),s("td",[t._v("读取默认以制表符分隔的文件")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_fwf")]),t._v(" "),s("td",[t._v("从特定宽度格式的文件中读取数据（无分隔符）")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_clipboard")]),t._v(" "),s("td",[s("code",[t._v("read_table")]),t._v("的剪贴板版本")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_excel")]),t._v(" "),s("td",[t._v("从EXCEL的XLS或者XLSX文件中读取数据")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_hdf")]),t._v(" "),s("td",[t._v("读取用pandas存储的HDF5文件")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_html")]),t._v(" "),s("td",[t._v("从HTML文件中读取所有表格数据")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_json")]),t._v(" "),s("td",[t._v("从JSON字符串中读取数据")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_msgpack")]),t._v(" "),s("td",[t._v("读取MessagePack格式存储的任意对象")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_pickle")]),t._v(" "),s("td",[t._v("读取以Python Pickle格式存储的对象")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_sas")]),t._v(" "),s("td",[t._v("读取SAS系统中定制存储格式的数据集")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_sql")]),t._v(" "),s("td",[t._v("将SQL查询的结果读取出来")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_stata")]),t._v(" "),s("td",[t._v("读取stata格式的数据集")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("read_feather")]),t._v(" "),s("td",[t._v("读取Feather二进制格式")])])])]),t._v(" "),s("ul",[s("li",[s("p",[t._v("在Pandas的使用场景中，最多的是将表格型的数据读取为DataFrame对象。实现这一功能的函数有很多，最常用的是"),s("code",[t._v("read_csv")]),t._v("和"),s("code",[t._v("read_table")]),t._v("。")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("通常第一行默认会被当成列索引，需要设置head=None")])]),t._v(" "),s("li",[s("p",[t._v('设置sep=""(支持正则)指定分隔符（这种情况下read_csv 和read_table没有什么区别）')])]),t._v(" "),s("li",[s("p",[t._v("设置usecols指定读取哪些列")])]),t._v(" "),s("li",[s("p",[t._v("设置skiprows指定跳过哪些行")])]),t._v(" "),s("li",[s("p",[t._v("设置na_values指定将哪些值当成缺失值看待")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("In "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d:/ex5.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" result\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  something  a   b     c   d message\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("       one  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.0")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("     NaN\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       two  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("   NaN   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("   world\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     three  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11.0")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("     foo\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d:/ex5.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("na_values"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("41")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" result\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("41")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  something  a   b     c   d message\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("       one  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   NaN   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("     NaN\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       two  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("   NaN   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("   world\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     three  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11.0")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("     foo\n")])])]),s("ul",[s("li",[s("p",[t._v("可以为不同列指定不同的缺失值标识-传入列名为键的字典即可")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("In "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" f "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'message'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'foo'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'NA'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'something'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'two'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("43")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d:/ex5.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("na_values"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("44")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" result\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("44")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  something  a   b     c   d message\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("       one  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.0")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("     NaN\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       NaN  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("   NaN   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("   world\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("     three  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11.0")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("     NaN\n")])])])]),t._v(" "),s("li",[s("p",[t._v("‍")])])])]),t._v(" "),s("li",[s("p",[t._v("常用参数如下：")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("参数")]),t._v(" "),s("th",[t._v("说明")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("path")]),t._v(" "),s("td",[t._v("文件路径")])]),t._v(" "),s("tr",[s("td",[t._v("sep")]),t._v(" "),s("td",[t._v("指定分隔符或正则表达式")])]),t._v(" "),s("tr",[s("td",[t._v("header")]),t._v(" "),s("td",[t._v("用作列名的行号")])]),t._v(" "),s("tr",[s("td",[t._v("index_col")]),t._v(" "),s("td",[t._v("用作行索引的列名或列号")])]),t._v(" "),s("tr",[s("td",[t._v("names")]),t._v(" "),s("td",[t._v("结果的列名列表")])]),t._v(" "),s("tr",[s("td",[t._v("skiprows")]),t._v(" "),s("td",[t._v("从起始处，需要跳过的行")])]),t._v(" "),s("tr",[s("td",[t._v("na_values")]),t._v(" "),s("td",[t._v("需要用NaN替换的值")])]),t._v(" "),s("tr",[s("td",[t._v("comment")]),t._v(" "),s("td",[t._v("在行结尾处分隔注释的字符")])]),t._v(" "),s("tr",[s("td",[t._v("parse_dates")]),t._v(" "),s("td",[t._v("尝试将数据解析为datetime，默认是False")])]),t._v(" "),s("tr",[s("td",[s("code",[t._v("keep_date_col")])]),t._v(" "),s("td",[t._v("如果连接列到解析日期上，保留被连接的列，默认False")])]),t._v(" "),s("tr",[s("td",[t._v("converters")]),t._v(" "),s("td",[t._v("包含列名称映射到函数的字典")])]),t._v(" "),s("tr",[s("td",[t._v("dayfirst")]),t._v(" "),s("td",[t._v("解析非明确日期时，按国际格式处理")])]),t._v(" "),s("tr",[s("td",[t._v("date_parser")]),t._v(" "),s("td",[t._v("用于解析日期的函数")])]),t._v(" "),s("tr",[s("td",[t._v("nrows")]),t._v(" "),s("td",[t._v("从文件开头处读入的行数")])]),t._v(" "),s("tr",[s("td",[t._v("iterator")]),t._v(" "),s("td",[t._v("返回一个TextParser对象，用于零散地读入文件")])]),t._v(" "),s("tr",[s("td",[t._v("chunksize")]),t._v(" "),s("td",[t._v("用于迭代的块大小")])]),t._v(" "),s("tr",[s("td",[t._v("skip_footer")]),t._v(" "),s("td",[t._v("忽略文件尾部的行数")])]),t._v(" "),s("tr",[s("td",[t._v("verbose")]),t._v(" "),s("td",[t._v("打印各种解析器输出的信息")])]),t._v(" "),s("tr",[s("td",[t._v("encoding")]),t._v(" "),s("td",[t._v("文本编码，比如UTF-8")])]),t._v(" "),s("tr",[s("td",[t._v("thousands")]),t._v(" "),s("td",[t._v("定义千位分隔符，例如逗号或者圆点")])])])])])])]),t._v(" "),s("li",[s("p",[t._v("使用"),s("code",[t._v("read_json")]),t._v("​函数可以自动将JSON数据集按照指定的顺序转换为Series或者DataFrame对象，其默认做法是假设JSON数据中的每个对象是表里的一行")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("\n\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("81")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d:/example.json'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("82")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" data\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("82")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   a  b  c\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("\n")])])]),s("ul",[s("li",[s("p",[t._v("使用to_json函数可以将pandas对象转换为json格式")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("In "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("83")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"c"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])]),t._v(" "),s("li",[s("p",[t._v("‍")])])])]),t._v(" "),s("li",[s("p",[t._v("使用read_excel和write_excel从Excle 2003或更高版本文件中读写数据")]),t._v(" "),s("ul",[s("li",[s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("In "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("106")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" df "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_excel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d:/ex1.xlsx'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Sheet1'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 读取指定的表")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("107")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" df\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("107")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   a   b   c   d message\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("   hello\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v("   world\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("     foo\n")])])])]),t._v(" "),s("li",[s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_excel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d:/ex3.xlsx'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])])]),t._v(" "),s("li",[s("p",[t._v("文件分块读取")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("设置nrows指定从文件开始只读取前n行")])]),t._v(" "),s("li",[s("p",[t._v("设置chunksize作为每一块的行数，分块读入文件")]),t._v(" "),s("ul",[s("li",[t._v("返回的结果是一个可迭代对象")]),t._v(" "),s("li",[s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("In "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" chunker "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'d:/ex6.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" chunksize"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("51")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" chunker\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("51")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("pandas"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parsers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TextFileReader at "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0x2417d6cfb38")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])])]),t._v(" "),s("li",[s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 遍历并对‘key’列进行聚合获得计数值：")]),t._v("\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("52")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" total "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Series"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("53")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" piece "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" chunker"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("     total "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" total"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("piece"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'key'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value_counts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fill_value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" total "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" total"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sort_values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ascending"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("54")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" total\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("54")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\nE    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("368.0")]),t._v("\nX    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("364.0")]),t._v("\nL    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("346.0")]),t._v("\nO    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("343.0")]),t._v("\nQ    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("340.0")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("157.0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("152.0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("151.0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("150.0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("146.0")]),t._v("\nLength"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("36")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dtype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" float64\n\nIn "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("55")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" total"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nOut"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("55")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\nE    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("368.0")]),t._v("\nX    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("364.0")]),t._v("\nL    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("346.0")]),t._v("\nO    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("343.0")]),t._v("\nQ    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("340.0")]),t._v("\nM    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("338.0")]),t._v("\nJ    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("337.0")]),t._v("\nF    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("335.0")]),t._v("\nK    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("334.0")]),t._v("\nH    "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("330.0")]),t._v("\ndtype"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" float64\n")])])])])])])])]),t._v(" "),s("li",[s("p",[t._v("‍")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);